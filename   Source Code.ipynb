{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1h2fxKtsei8cNS6m2G-jMhBx0WifoFXyx","timestamp":1747064845769},{"file_id":"1w_psPOeyweK-IJcpZJCSVj5bcPbDnkQF","timestamp":1747064815560}],"authorship_tag":"ABX9TyMlQp/gNWvQ1vIJcbyyBQmM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"z_xbe5BB9P8L"},"outputs":[],"source":["\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import re\n","import string\n","from wordcloud import WordCloud\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report, confusion_matrix\n","df = pd.read_csv('emotion_dataset.csv')  # Make sure to have a dataset with 'text' and 'emotion' columns\n","       print(df.head())\n","def clean_text(text):\n","    text = re.sub(r\"http\\S+\", \"\", text)  # remove URLs\n","    text = text.lower()\n","    text = text.translate(str.maketrans('', '', string.punctuation))\n","    return text\n","df['clean_text'] = df['text'].apply(clean_text)\n","sns.countplot(x='emotion', data=df)\n","plt.title('Distribution of Emotions')\n","plt.xticks(rotation=45)\n","plt.tight_layout()\n","plt.show()\n","emotion_types = df[‘emotion’].unique()\n","for emotion in emotion_types:\n","    text = ‘ ‘.join(df[df[‘emotion’] == emotion][‘clean_text’])\n","    wordcloud = WordCloud(width=800, height=400, background_color=’white’).generate(text)\n","    plt.figure(figsize=(10, 5))\n","    plt.imshow(wordcloud, interpolation=’bilinear’)\n","    plt.title(f’WordCloud for {emotion}’)\n","    plt.axis(‘off’)\n","    plt.show()\n","X = df[‘clean_text’]\n","Y = df[‘emotion’]\n","\n","Vectorizer = TfidfVectorizer(max_features=5000)\n","X_vec = vectorizer.fit_transform(X)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2, random_state=42)\n","model = LogisticRegression(max_iter=1000)\n","model.fit(X_train, y_train)\n","y_pred = model.predict(X_test)\n","\n","print(\"Classification Report:\")\n","print(classification_report(y_test, y_pred))\n","\n","cm = confusion_matrix(y_test, y_pred)\n","sns.heatmap(cm, annot=True, fmt='d', xticklabels=model.classes_, yticklabels=model.classes_, cmap='Blues')\n","plt.xlabel('Predicted')\n","plt.ylabel('Actual')\n","plt.title('Confusion Matrix')\n","plt.show()\n","def predict_emotion(text):\n","    cleaned = clean_text(text)\n","    vec = vectorizer.transform([cleaned])\n","    return model.predict(vec)[0]\n","Print(predict_emotion(“I’m so excited about this!”))"]}]}